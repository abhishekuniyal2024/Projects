{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165ebbb7",
   "metadata": {},
   "source": [
    "# Text extraction using OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90df4ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Text:\n",
      "------------------------------\n",
      "B aimol.txt x + ~ a x\n",
      "\n",
      "File Edit View Ww. £33\n",
      "IAI/ML Notes\n",
      "\n",
      "1.1 Artificial Intelligence (AI)\n",
      "\n",
      "* Definition: Creating machines that simulate human intelligence (learning, reasoning, problem-solving, perception, decision-\n",
      "making).\n",
      "\n",
      "* Examples: Chatbots (ChatGPT, Siri), Computer Vision (Face recognition), Autonomous Vehicles (Tesla), Healthcare AI (Disease\n",
      "prediction), Finance AI (Stock market prediction).\n",
      "\n",
      "1.2 Machine Learning (ML)\n",
      "\n",
      "* Definition: Subset of AI where machines learn from data without explicit programming.\n",
      "\n",
      "* Types: 1. Supervised (labeled data, e.g., spam detection), 2. Unsupervised (unlabeled data, e.g., customer segmentation),\n",
      "3. Reinforcement (trial and error, e.g., AlphaGo).\n",
      "\n",
      "* Examples: Recommendation Systems (Netflix, YouTube), Fraud Detection, Self-Driving Cars, Medical Diagnosis.\n",
      "\n",
      "1.3 AI vs. ML\n",
      "* AT is the broader concept; ML is a way to achieve AI.\n",
      "* ML models learn from data; AI can involve pre-programmed logic.\n",
      "\n",
      "II. Machine Learning Algorithms\n",
      "2.1 Supervised Learning (learns from labeled data)\n",
      "\n",
      "* 2.1.1 Linear Regression: Predicts continuous output. Metrics: MSE, RMSE, R-squared. Pros: Simple. Cons: Linear, outliers.\n",
      "Use Cases: House prices, sales.\n",
      "\n",
      "* 2.1.2 Logistic Regression: Predicts categorical output (binary). Metrics: Accuracy, Precision, Recall, F1, AUC-ROC. Pros:\n",
      "Easy, probability. Cons: Linearity, multicollinearity. Use Cases: Spam, diagnosis.\n",
      "\n",
      "* 2.1.3 SVM: Maximizes margin between classes. Pros: High-dimensional, versatile. Cons: Expensive, tuning. Use Cases: Image,\n",
      "\n",
      "Ln1 Colt 6.999 characters 106% Windows iCRLF UTF-8\n",
      "------------------------------\n",
      "Recognized text saved to: E:\\Ducat\\AiProjects\\Text_OCR\\extracted_text.txt\n"
     ]
    }
   ],
   "source": [
    "# text extraction using OCR\n",
    "import cv2\n",
    "import pytesseract\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Set up Tesseract-OCR path\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "# Read image\n",
    "image_path = r\"E:\\Ducat\\AiProjects\\Text_OCR\\Real_text_image.png\"\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Get image directory\n",
    "image_dir = os.path.dirname(image_path)\n",
    "output_text_path = os.path.join(image_dir, \"extracted_text.txt\")\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply Bilateral Filter (preserves edges better than Gaussian Blur)\n",
    "gray = cv2.bilateralFilter(gray, 9, 75, 75)\n",
    "\n",
    "# Use Otsu's Thresholding instead of Adaptive (better for printed text)\n",
    "_, processed_img = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Resize image to increase DPI (helps Tesseract)\n",
    "scale_factor = 2  # Increase resolution\n",
    "processed_img = cv2.resize(processed_img, None, fx=scale_factor, fy=scale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# Save processed image for debugging\n",
    "cv2.imwrite(os.path.join(image_dir, \"preprocessed_img.png\"), processed_img)\n",
    "\n",
    "# Apply OCR with optimized settings\n",
    "custom_config = r'--oem 3 --psm 4'  # Try --psm 11 if output is still distorted\n",
    "extracted_text = pytesseract.image_to_string(processed_img, config=custom_config, lang='eng')\n",
    "\n",
    "# Print extracted text\n",
    "print(\"\\nExtracted Text:\\n\" + \"-\" * 30)\n",
    "print(extracted_text.strip())\n",
    "\n",
    "# Save text to file\n",
    "with open(output_text_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(extracted_text.strip())\n",
    "\n",
    "print(\"-\" * 30 + f\"\\nRecognized text saved to: {output_text_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df688099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character-Level Accuracy: 93.54%\n",
      "Word-Level Accuracy: 90.55%\n",
      "Sequence Matching Score: 96.63%\n"
     ]
    }
   ],
   "source": [
    "# check accuracy of model\n",
    "\n",
    "from difflib import SequenceMatcher, get_close_matches\n",
    "import Levenshtein\n",
    "import re\n",
    "\n",
    "actual_text_path = r\"E:\\Ducat\\Deep Learning\\Text_OCR\\actual_text.txt\"\n",
    "extracted_text_path = r\"E:\\Ducat\\Deep Learning\\Text_OCR\\extracted_text.txt\"\n",
    "\n",
    "# Load texts\n",
    "with open(actual_text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    actual_text = f.read().strip()\n",
    "\n",
    "with open(extracted_text_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    extracted_text = f.read().strip()\n",
    "\n",
    "# === Improved Preprocessing ===\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Normalize spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    return text.strip()\n",
    "\n",
    "actual_text = clean_text(actual_text)\n",
    "extracted_text = clean_text(extracted_text)\n",
    "\n",
    "# === Character-Level Accuracy (Levenshtein Distance) ===\n",
    "lev_distance = Levenshtein.distance(actual_text, extracted_text)\n",
    "char_accuracy = (1 - lev_distance / max(len(actual_text), len(extracted_text))) * 100\n",
    "\n",
    "# === Word-Level Accuracy (Using Better Matching) ===\n",
    "ground_words = actual_text.split()\n",
    "extracted_words = extracted_text.split()\n",
    "\n",
    "matched_words = 0\n",
    "for word in extracted_words:\n",
    "    if word in ground_words or get_close_matches(word, ground_words, n=1, cutoff=0.8):\n",
    "        matched_words += 1\n",
    "\n",
    "word_accuracy = (matched_words / max(len(ground_words), len(extracted_words))) * 100\n",
    "\n",
    "# === Sequence Matching Score ===\n",
    "sequence_match = SequenceMatcher(None, actual_text, extracted_text).ratio() * 100\n",
    "\n",
    "# === Print Results ===\n",
    "print(f\"Character-Level Accuracy: {char_accuracy:.2f}%\")\n",
    "print(f\"Word-Level Accuracy: {word_accuracy:.2f}%\")\n",
    "print(f\"Sequence Matching Score: {sequence_match:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe61f93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f147dbe-7ab1-40ee-a8df-dc1c0f57a3df",
   "metadata": {},
   "source": [
    "# **Text Extraction and Accuracy Evaluation Using Tesseract OCR**\n",
    "\n",
    "## **Objective**\n",
    "The objective of this project is to extract text from an image using Tesseract OCR and evaluate its accuracy by comparing it with the actual text. The accuracy is measured using character-level, word-level, and sequence matching techniques.\n",
    "\n",
    "---\n",
    "\n",
    "## **Steps Involved**\n",
    "\n",
    "### **1. Image Preprocessing**\n",
    "- Load the image using OpenCV.\n",
    "- Convert the image to grayscale.\n",
    "- Apply a bilateral filter to reduce noise while preserving edges.\n",
    "- Use Otsu’s thresholding to binarize the image.\n",
    "- Resize the image to increase resolution and improve OCR performance.\n",
    "\n",
    "### **2. Text Extraction Using Tesseract OCR**\n",
    "- Use Tesseract OCR with optimized configurations (`--oem 3 --psm 4`).\n",
    "- Extract text from the preprocessed image.\n",
    "- Save the extracted text to a file.\n",
    "\n",
    "### **3. Accuracy Evaluation**\n",
    "- Load the actual text and extracted text from files.\n",
    "- Preprocess the texts by:\n",
    "  - Converting to lowercase.\n",
    "  - Removing extra spaces and punctuation.\n",
    "- Compute accuracy using three different metrics:\n",
    "  - **Character-Level Accuracy:** Based on Levenshtein distance.\n",
    "  - **Word-Level Accuracy:** Using exact matches and close matches.\n",
    "  - **Sequence Matching Score:** Using `SequenceMatcher`.\n",
    "\n",
    "---\n",
    "\n",
    "## **Results and Conclusion**\n",
    "- The extracted text was compared with the actual text, and the following accuracy scores were obtained:\n",
    "  - **Character-Level Accuracy:** 93.54%\n",
    "  - **Word-Level Accuracy:** 90.55%\n",
    "  - **Sequence Matching Score:** 96.63%\n",
    "- The high accuracy scores indicate that the OCR process is effective for structured and clear text images.\n",
    "- Minor errors may still occur due to image noise, font variations, or distortions.\n",
    "- Further improvements can be achieved by fine-tuning preprocessing techniques and testing different Tesseract parameters.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fb9033-9e59-4664-8e59-c103f42f8cae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
